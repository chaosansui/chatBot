from typing import List
from loguru import logger
import os
from core.config import settings
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document
from langchain_community.document_loaders import PyPDFLoader, TextLoader 
from langchain.text_splitter import RecursiveCharacterTextSplitter

from langchain_community.embeddings import HuggingFaceBgeEmbeddings
from langchain_milvus import Milvus
from pymilvus import connections, utility



class RAGService:
    """RAG æœåŠ¡ï¼šä½¿ç”¨ Milvus ä½œä¸ºå‘é‡å­˜å‚¨ï¼ŒBGE-M3 ä½œä¸ºåµŒå…¥æ¨¡å‹"""
    
    def __init__(self):
        # 1. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ (Embedding Model) - ä½¿ç”¨ BGE-M3
        self.embedding_model_name = "BAAI/bge-m3"
        self.collection_name = settings.MILVUS_COLLECTION_NAME # ä¾‹å¦‚: "rag_documents"
        
        try:
            # BGE-M3 æ˜¯å¤šè¯­è¨€æ¨¡å‹ï¼Œé»˜è®¤åŠ è½½æ–¹å¼å¦‚ä¸‹
            self.embeddings = HuggingFaceBgeEmbeddings(model_name=self.embedding_model_name)
            logger.info(f"âœ… åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ: {self.embedding_model_name}")
        except Exception as e:
            logger.error(f"âŒ åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹ä¸‹è½½: {e}")
            self.embeddings = None
        
        # 2. åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=settings.RAG_CHUNK_SIZE,     # å»ºè®® BGE-M3 ä½¿ç”¨å¤§å°ºå¯¸ï¼Œä¾‹å¦‚ 800-1024
            chunk_overlap=settings.RAG_CHUNK_OVERLAP, # ä¾‹å¦‚: 50-100
            length_function=len,
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", " ", ""] 
        )

        # 3. è¿æ¥ Milvus æ•°æ®åº“
        self.milvus_host = settings.MILVUS_HOST
        self.milvus_port = settings.MILVUS_PORT
        self.vector_store = None
        self._connect_milvus()


    def _connect_milvus(self):
        """å°è¯•è¿æ¥ Milvus å¹¶åˆå§‹åŒ– Milvus å‘é‡å­˜å‚¨å®¢æˆ·ç«¯"""
        if not self.embeddings:
            logger.error("åµŒå…¥æ¨¡å‹æœªå°±ç»ªï¼Œæ— æ³•è¿æ¥ Milvusã€‚")
            return
            
        try:
            # åˆ›å»º Milvus è¿æ¥
            connections.connect(
                alias="default", 
                host=self.milvus_host, 
                port=self.milvus_port
            )
            
            # æ£€æŸ¥è¿æ¥æ˜¯å¦æˆåŠŸ
            if utility.has_connection("default"):
                logger.info(f"âœ… æˆåŠŸè¿æ¥åˆ° Milvus æœåŠ¡ï¼š{self.milvus_host}:{self.milvus_port}")
                
                # åˆå§‹åŒ– LangChain Milvus å®¢æˆ·ç«¯
                self.vector_store = Milvus(
                    embedding_function=self.embeddings,
                    collection_name=self.collection_name,
                    connection_args={"host": self.milvus_host, "port": self.milvus_port},
                    auto_id=True, # ä½¿ç”¨ Milvus è‡ªåŠ¨ç”Ÿæˆçš„ ID
                    drop_old=False # å¯åŠ¨æ—¶ä¸åˆ é™¤æ—§çš„ Collection
                )
                logger.info(f"âœ… Milvus é›†åˆå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼š{self.collection_name}")
            else:
                logger.error("âŒ æ— æ³•å»ºç«‹ Milvus è¿æ¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€ã€‚")
                
        except Exception as e:
            logger.error(f"âŒ Milvus è¿æ¥æˆ–åˆå§‹åŒ–å¤±è´¥: {e}")

    async def process_data(self, file_paths: List[str]):
        """å¤„ç†ä¸€ç»„æ–‡ä»¶ï¼šåŠ è½½ã€åˆ‡åˆ†ã€åµŒå…¥å¹¶å­˜å‚¨åˆ° Milvusã€‚"""
        if not self.vector_store:
            logger.error("Milvus å‘é‡å­˜å‚¨æœªå‡†å¤‡å°±ç»ªï¼Œæ— æ³•å¤„ç†æ•°æ®ã€‚")
            return
            
        all_documents = []
        
        # 1. æ–‡æ¡£åŠ è½½ (ä¿æŒä¸å˜)
        # ... (åŠ è½½é€»è¾‘)
        for path in file_paths:
            try:
                if path.endswith(".pdf"):
                    loader = PyPDFLoader(path)
                elif path.endswith(".txt"):
                    loader = TextLoader(path, encoding='utf-8')
                else:
                    logger.warning(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œè·³è¿‡: {path}")
                    continue
                
                documents = loader.load()
                all_documents.extend(documents)
                logger.info(f"ğŸ“š æˆåŠŸåŠ è½½æ–‡æ¡£: {path}, é¡µæ•°/å—æ•°: {len(documents)}")
            except Exception as e:
                logger.error(f"åŠ è½½æ–‡ä»¶ {path} å¤±è´¥: {e}")

        if not all_documents:
            logger.warning("æ²¡æœ‰å¯å¤„ç†çš„æ–‡æ¡£ã€‚")
            return

        # 2. æ–‡æœ¬åˆ‡åˆ† (Chunking)
        texts = self.text_splitter.split_documents(all_documents)
        logger.info(f"âœ‚ï¸ æ–‡æ¡£åˆ‡åˆ†å®Œæˆï¼Œæ€»è®¡ {len(texts)} ä¸ªæ–‡æœ¬å—ã€‚")

        # 3. åµŒå…¥å¹¶å­˜å‚¨åˆ° Milvus
        try:
            # LangChain Milvus å®¢æˆ·ç«¯çš„ add_documents ä¼šè‡ªåŠ¨å¤„ç†åµŒå…¥å’Œæ’å…¥
            self.vector_store.add_documents(texts)
            logger.info(f"âš¡ï¸ {len(texts)} ä¸ªæ–‡æœ¬å—å·²æˆåŠŸåµŒå…¥å¹¶å­˜å‚¨åˆ° Milvus é›†åˆ {self.collection_name}ã€‚")
        except Exception as e:
            logger.error(f"âŒ åµŒå…¥å¹¶å­˜å‚¨åˆ° Milvus å¤±è´¥: {e}")


    def get_retriever(self) -> BaseRetriever:
        """å¯¹å¤–æä¾› Milvus æ£€ç´¢å™¨å®ä¾‹ã€‚"""
        if not self.vector_store:
            logger.error("Milvus å‘é‡å­˜å‚¨æœªå‡†å¤‡å°±ç»ªï¼Œæ£€ç´¢å™¨è¿”å›ç©ºã€‚")
            from langchain_core.retrievers import create_base_retriever
            return create_base_retriever(lambda x: []) 
        
        # ä½¿ç”¨ Milvus çš„é»˜è®¤æ£€ç´¢å™¨
        return self.vector_store.as_retriever(
            search_type="similarity", # Milvus æ£€ç´¢ç±»å‹
            search_kwargs={"k": settings.RAG_TOP_K}
        )

# å…¨å±€ RAG æœåŠ¡å®ä¾‹
rag_service = RAGService()